import pyspark 
from pyspark.sql import SparkSession
from pyspark.sql import functions as F


data_path = '/home/idowuileks/Desktop/tech_project/nyc_taxi_project/docker_sql/etl_script/data/2023_data/yellow_tripdata_2023-01.parquet'


spark = SparkSession.builder.master("local[*]").appName("test").getOrCreate()
spark.conf.set("spark.sql.execution.arrow.pyspark.enabled", "true")


df = spark.read.option("header","true").format("parquet").load(data_path,inferSchema="true")


def get_date_info_pyspark(df, column, new_column_prefix):
  """
  Extracts various date information from a PySpark DataFrame column.

  Args:
    df: The PySpark DataFrame.
    column: The name of the date column.
    new_column_prefix: The prefix for the new columns containing date information.

  Returns:
    The modified DataFrame with new columns containing year, month, day, hour, minute,
    day of week, day name, month-end flag, and year-end flag.
  """

  df = df.withColumn(f"{new_column_prefix}_year", F.year(F.col(column)))
  df = df.withColumn(f"{new_column_prefix}_month", F.month(F.col(column)))
  df = df.withColumn(f"{new_column_prefix}_day", F.dayofmonth(F.col(column)))
  df = df.withColumn(f"{new_column_prefix}_hour", F.hour(F.col(column)))
  df = df.withColumn(f"{new_column_prefix}_minute", F.minute(F.col(column)))
  df = df.withColumn(f"{new_column_prefix}_day_of_week", F.dayofweek(column))
  df = df.withColumn(f"{new_column_prefix}_day_name", F.date_format(column, "EEEE"))
  df = df.withColumn(f"{new_column_prefix}_month_name", F.date_format(column, "MMMM"))
  df = df.withColumn(f"{new_column_prefix}_is_month_end", F.last_day(F.col(column)) == F.col(column))
#   df = df.withColumn(f"{new_column_prefix}_is_year_end", F.last_day(column) == F.date_add(
#       F.last_day(column), F.months(1) - F.dayofmonth(column)
#   ))
  return df


df_time_table_pickup = get_date_info_pyspark(df,'tpep_dropoff_datetime','pickup')

df_time_table_pickup.show()


print(df_time_table_pickup.head())


df_time_table_pickup.limit(10).toPandas()


# pd.read_clipboard('


df = spark.createDataFrame([('1997-02-10',)], ['d'])

# df.select(last_day(df.d).alias('date')).collect()


from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit, lower, to_timestamp, date_format, udf, monotonically_increasing_id

def transform_data_pyspark(data_df):
    """
    Transforms a PySpark DataFrame containing taxi trip data into dimension and fact tables.

    Args:
        data_df (pyspark.sql.DataFrame): The input DataFrame containing taxi trip data.

    Returns:
        Tuple(pyspark.sql.DataFrame, pyspark.sql.DataFrame, pyspark.sql.DataFrame):
            - dimension_table: The dimension table containing date-related and static attributes.
            - time_table: The time table containing extracted date and time components from timestamps.
            - fact_table: The fact table containing aggregated trip metrics associated with datetimes.
    """

    # Lowercase column names for consistency
    data_df = data_df.withColumnRenamed('*', lower(col('*')))

    # Define fact and dimension table columns
    fact_columns = [
        'tpep_dropoff_datetime', 'tpep_pickup_datetime', 'passenger_count', 'trip_distance',
        'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',
        'total_amount', 'congestion_surcharge', 'airport_fee'
    ]
    dimension_columns = [
        'tpep_dropoff_datetime', 'tpep_pickup_datetime', 'ratecodeid', 'store_and_fwd_flag',
        'pulocationid', 'dolocationid', 'payment_type'
    ]

    # Extract date and time components using to_timestamp and date_format
    time_table_df = data_df.select(
        'tpep_dropoff_datetime', 'tpep_pickup_datetime'
    ).withColumn('tpep_dropoff_datetime', to_timestamp(col('tpep_dropoff_datetime'))) \
       .withColumn('tpep_pickup_datetime', to_timestamp(col('tpep_pickup_datetime'))) \
       .withColumn('pickup_year', date_format(col('tpep_pickup_datetime'), 'yyyy')) \
       .withColumn('pickup_month', date_format(col('tpep_pickup_datetime'), 'MM')) \
       .withColumn('pickup_day', date_format(col('tpep_pickup_datetime'), 'dd')) \
       .withColumn('pickup_hour', date_format(col('tpep_pickup_datetime'), 'HH')) \
       .withColumn('pickup_minute', date_format(col('tpep_pickup_datetime'), 'mm')) \
       .withColumn('pickup_day_of_week', date_format(col('tpep_pickup_datetime'), 'E')) \
       .withColumn('pickup_day_name', date_format(col('tpep_pickup_datetime'), 'EEEE')) \
       .withColumn('pickup_is_month_end', date_format(col('tpep_pickup_datetime'), 'd').cast('int') == 31) \
       .withColumn('pickup_is_year_end', date_format(col('tpep_pickup_datetime'), 'MM').cast('int') == 12) \
       .withColumn('dropoff_year', date_format(col('tpep_dropoff_datetime'), 'yyyy')) \
       .withColumn('dropoff_month', date_format(col('tpep_dropoff_datetime'), 'MM')) \
       .withColumn('dropoff_day', date_format(col('tpep_dropoff_datetime'), 'dd')) \
       .withColumn('dropoff_hour', date_format(col('tpep_dropoff_datetime'), 'HH')) \
       .withColumn('dropoff_minute', date_format(col('tpep_dropoff_datetime'), 'mm')) \
       .withColumn('dropoff_day_of_week', date_format(col('tpep_dropoff_datetime'), 'E')) \
       .withColumn('dropoff_day_name', date_format(col('tpep_dropoff_datetime'), 'EEEE')) \
       .withColumn('dropoff_is_month_end', date_format(col('tpep_dropoff_

