[2024-02-29T05:30:57.202+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: run_pipeline_new.download_load_data scheduled__2021-10-01T00:00:00+00:00 [queued]>
[2024-02-29T05:30:57.229+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: run_pipeline_new.download_load_data scheduled__2021-10-01T00:00:00+00:00 [queued]>
[2024-02-29T05:30:57.230+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 3
[2024-02-29T05:30:57.272+0000] {taskinstance.py:2214} INFO - Executing <Task(PythonOperator): download_load_data> on 2021-10-01 00:00:00+00:00
[2024-02-29T05:30:57.278+0000] {standard_task_runner.py:60} INFO - Started process 1287188 to run task
[2024-02-29T05:30:57.299+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'run_pipeline_new', 'download_load_data', 'scheduled__2021-10-01T00:00:00+00:00', '--job-id', '64', '--raw', '--subdir', 'DAGS_FOLDER/run_pipeline.py', '--cfg-path', '/tmp/tmpi70lwwzc']
[2024-02-29T05:30:57.301+0000] {standard_task_runner.py:88} INFO - Job 64: Subtask download_load_data
[2024-02-29T05:30:57.554+0000] {task_command.py:423} INFO - Running <TaskInstance: run_pipeline_new.download_load_data scheduled__2021-10-01T00:00:00+00:00 [running]> on host idowu-pc
[2024-02-29T05:30:58.037+0000] {logging_mixin.py:188} WARNING - /home/idowuileks/Desktop/tech_project/nyc_taxi_project/docker_sql/ny_taxi_test/dbtairflowenv/lib/python3.10/site-packages/airflow/utils/context.py:207 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2024-02-29T05:30:58.199+0000] {taskinstance.py:2510} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='run_pipeline_new' AIRFLOW_CTX_TASK_ID='download_load_data' AIRFLOW_CTX_EXECUTION_DATE='2021-10-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2021-10-01T00:00:00+00:00'
[2024-02-29T05:30:58.200+0000] {logging_mixin.py:188} INFO - <class 'str'>
[2024-02-29T05:30:58.200+0000] {logging_mixin.py:188} INFO - <class 'str'>
[2024-02-29T05:30:58.200+0000] {logging_mixin.py:188} INFO - /home/idowuileks/Desktop/tech_project/nyc_taxi_project/docker_sql/etl_script/data/2021_10_data
[2024-02-29T05:31:05.655+0000] {logging_mixin.py:188} INFO - /home/idowuileks/Desktop/tech_project/nyc_taxi_project/docker_sql/etl_script/data/2021_10_data/yellow_tripdata_2021-10.parquet
[2024-02-29T05:31:29.203+0000] {logging_mixin.py:188} INFO - running the create_table_load_data
[2024-02-29T05:31:29.237+0000] {logging_mixin.py:188} INFO - created the table and schema datetime_trip_table and raw
[2024-02-29T05:31:29.238+0000] {logging_mixin.py:188} INFO - about to execute read_load_data_db
[2024-02-29T05:31:29.238+0000] {logging_mixin.py:188} INFO - about to read the previous data from the raw.datetime_trip_table
[2024-02-29T05:31:29.277+0000] {logging_mixin.py:188} INFO - (10, 19)
[2024-02-29T05:32:06.265+0000] {logging_mixin.py:188} INFO - got the previous records
[2024-02-29T05:32:06.265+0000] {logging_mixin.py:188} INFO - appending to table datetime_trip_table with raw
[2024-02-29T05:51:27.104+0000] {logging_mixin.py:188} INFO - running the create_table_load_data
[2024-02-29T05:51:27.111+0000] {logging_mixin.py:188} INFO - created the table and schema DIMENSION_TAXI_TABLE and raw
[2024-02-29T05:51:27.111+0000] {logging_mixin.py:188} INFO - about to execute read_load_data_db
[2024-02-29T05:51:27.112+0000] {logging_mixin.py:188} INFO - about to read the previous data from the raw.DIMENSION_TAXI_TABLE
[2024-02-29T05:51:27.140+0000] {logging_mixin.py:188} INFO - (10, 6)
[2024-02-29T05:51:45.142+0000] {logging_mixin.py:188} INFO - got the previous records
[2024-02-29T05:51:45.142+0000] {logging_mixin.py:188} INFO - appending to table DIMENSION_TAXI_TABLE with raw
[2024-02-29T05:55:09.106+0000] {logging_mixin.py:188} INFO - running the create_table_load_data
[2024-02-29T05:55:09.116+0000] {logging_mixin.py:188} INFO - created the table and schema fact_table_taxi_ride and raw
[2024-02-29T05:55:09.118+0000] {logging_mixin.py:188} INFO - about to execute read_load_data_db
[2024-02-29T05:55:09.118+0000] {logging_mixin.py:188} INFO - about to read the previous data from the raw.fact_table_taxi_ride
[2024-02-29T05:55:09.127+0000] {logging_mixin.py:188} INFO - (10, 12)
[2024-02-29T05:55:20.226+0000] {logging_mixin.py:188} INFO - got the previous records
[2024-02-29T05:55:20.227+0000] {logging_mixin.py:188} INFO - appending to table fact_table_taxi_ride with raw
[2024-02-29T05:57:02.107+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-02-29T05:57:02.123+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=run_pipeline_new, task_id=download_load_data, execution_date=20211001T000000, start_date=20240229T053057, end_date=20240229T055702
[2024-02-29T05:57:02.176+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
