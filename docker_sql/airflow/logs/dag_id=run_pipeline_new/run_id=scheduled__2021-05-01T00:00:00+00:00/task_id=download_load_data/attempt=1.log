[2024-02-29T05:30:56.740+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: run_pipeline_new.download_load_data scheduled__2021-05-01T00:00:00+00:00 [queued]>
[2024-02-29T05:30:56.780+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: run_pipeline_new.download_load_data scheduled__2021-05-01T00:00:00+00:00 [queued]>
[2024-02-29T05:30:56.781+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 3
[2024-02-29T05:30:56.847+0000] {taskinstance.py:2214} INFO - Executing <Task(PythonOperator): download_load_data> on 2021-05-01 00:00:00+00:00
[2024-02-29T05:30:56.854+0000] {standard_task_runner.py:60} INFO - Started process 1287156 to run task
[2024-02-29T05:30:56.871+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'run_pipeline_new', 'download_load_data', 'scheduled__2021-05-01T00:00:00+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/run_pipeline.py', '--cfg-path', '/tmp/tmp2jqal4v7']
[2024-02-29T05:30:56.876+0000] {standard_task_runner.py:88} INFO - Job 61: Subtask download_load_data
[2024-02-29T05:30:57.133+0000] {task_command.py:423} INFO - Running <TaskInstance: run_pipeline_new.download_load_data scheduled__2021-05-01T00:00:00+00:00 [running]> on host idowu-pc
[2024-02-29T05:30:57.610+0000] {logging_mixin.py:188} WARNING - /home/idowuileks/Desktop/tech_project/nyc_taxi_project/docker_sql/ny_taxi_test/dbtairflowenv/lib/python3.10/site-packages/airflow/utils/context.py:207 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2024-02-29T05:30:57.878+0000] {taskinstance.py:2510} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='run_pipeline_new' AIRFLOW_CTX_TASK_ID='download_load_data' AIRFLOW_CTX_EXECUTION_DATE='2021-05-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2021-05-01T00:00:00+00:00'
[2024-02-29T05:30:57.883+0000] {logging_mixin.py:188} INFO - <class 'str'>
[2024-02-29T05:30:57.884+0000] {logging_mixin.py:188} INFO - <class 'str'>
[2024-02-29T05:30:57.888+0000] {logging_mixin.py:188} INFO - /home/idowuileks/Desktop/tech_project/nyc_taxi_project/docker_sql/etl_script/data/2021_05_data
[2024-02-29T05:31:06.766+0000] {logging_mixin.py:188} INFO - /home/idowuileks/Desktop/tech_project/nyc_taxi_project/docker_sql/etl_script/data/2021_05_data/yellow_tripdata_2021-05.parquet
[2024-02-29T05:31:28.439+0000] {logging_mixin.py:188} INFO - running the create_table_load_data
[2024-02-29T05:31:28.479+0000] {logging_mixin.py:188} INFO - created the table and schema datetime_trip_table and raw
[2024-02-29T05:31:28.480+0000] {logging_mixin.py:188} INFO - about to execute read_load_data_db
[2024-02-29T05:31:28.480+0000] {logging_mixin.py:188} INFO - about to read the previous data from the raw.datetime_trip_table
[2024-02-29T05:31:28.505+0000] {logging_mixin.py:188} INFO - (10, 19)
[2024-02-29T05:31:57.052+0000] {logging_mixin.py:188} INFO - got the previous records
[2024-02-29T05:31:57.053+0000] {logging_mixin.py:188} INFO - appending to table datetime_trip_table with raw
[2024-02-29T05:44:59.540+0000] {logging_mixin.py:188} INFO - running the create_table_load_data
[2024-02-29T05:44:59.561+0000] {logging_mixin.py:188} INFO - created the table and schema DIMENSION_TAXI_TABLE and raw
[2024-02-29T05:44:59.563+0000] {logging_mixin.py:188} INFO - about to execute read_load_data_db
[2024-02-29T05:44:59.563+0000] {logging_mixin.py:188} INFO - about to read the previous data from the raw.DIMENSION_TAXI_TABLE
[2024-02-29T05:44:59.578+0000] {logging_mixin.py:188} INFO - (10, 6)
[2024-02-29T05:45:05.735+0000] {logging_mixin.py:188} INFO - got the previous records
[2024-02-29T05:45:05.736+0000] {logging_mixin.py:188} INFO - appending to table DIMENSION_TAXI_TABLE with raw
[2024-02-29T05:49:36.464+0000] {logging_mixin.py:188} INFO - running the create_table_load_data
[2024-02-29T05:49:36.466+0000] {logging_mixin.py:188} INFO - created the table and schema fact_table_taxi_ride and raw
[2024-02-29T05:49:36.467+0000] {logging_mixin.py:188} INFO - about to execute read_load_data_db
[2024-02-29T05:49:36.467+0000] {logging_mixin.py:188} INFO - about to read the previous data from the raw.fact_table_taxi_ride
[2024-02-29T05:49:36.474+0000] {logging_mixin.py:188} INFO - (10, 12)
[2024-02-29T05:49:42.935+0000] {logging_mixin.py:188} INFO - got the previous records
[2024-02-29T05:49:42.936+0000] {logging_mixin.py:188} INFO - appending to table fact_table_taxi_ride with raw
[2024-02-29T05:51:55.907+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-02-29T05:51:56.044+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=run_pipeline_new, task_id=download_load_data, execution_date=20210501T000000, start_date=20240229T053056, end_date=20240229T055156
[2024-02-29T05:51:56.186+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
